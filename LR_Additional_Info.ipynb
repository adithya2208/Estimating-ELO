{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import figure\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../Project/finding-elo/')\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = sc.textFile('data_uci.pgn')\n",
    "games = games.map(lambda l:l.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(a):\n",
    "    if \"1/2\" in a:\n",
    "        return 0\n",
    "    if \"1-0\" in a:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def eval_moves(moves):\n",
    "    score = 0\n",
    "    for i in range(len(moves)-1):\n",
    "        score = score + moves[i+1] - moves[i]\n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = games.filter(lambda l:\"Result\" in l).map(lambda l: myfunc(l)).zipWithIndex().filter(lambda vi: vi[1] < 25000).map(lambda l:(l[1],l[0]))\n",
    "whiteelo = games.filter(lambda l: \"WhiteElo\" in l).map(lambda l:int(l.split()[1][1:5])).zipWithIndex().map(lambda l:(l[1],l[0]))\n",
    "blackelo = games.filter(lambda l: \"BlackElo\" in l).map(lambda l:int(l.split()[1][1:5])).zipWithIndex().map(lambda l:(l[1],l[0]))\n",
    "stockfish = sc.textFile('stockfish.csv').filter(lambda l: 'Event' not in l).map(lambda l:[0]+[int(x) for x in l.split(',')[1].split(\" \") if x!=''])\\\n",
    ".map(lambda l: eval_moves(l)).zipWithIndex().filter(lambda vi: vi[1] < 25000).map(lambda l:(l[1],l[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = whiteelo.join(blackelo).join(result).join(stockfish).map(lambda l:[l[1][0][0][0],l[1][0][0][1],l[1][0][0][0]-l[1][0][0][1],l[1][0][1],l[1][1]])\n",
    "df = temp.toDF(['white_rating','black_rating','rating_diff','result','score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------------------+\n",
      "|        prediction|white_rating|            features|\n",
      "+------------------+------------+--------------------+\n",
      "|1906.2080488812887|        1248|[-706.0,-1.0,-149...|\n",
      "|1914.4021039104302|        1784|[-684.0,-1.0,-450.0]|\n",
      "| 1946.628840963238|        1799|[-635.0,-1.0,-484...|\n",
      "| 1946.104577511845|        1361|[-617.0,-1.0,-521.0]|\n",
      "|1951.1054312514277|        1805|[-607.0,-1.0,-661.0]|\n",
      "+------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['rating_diff','result','score'], outputCol = \"features\")\n",
    "df = vectorAssembler.transform(df)\n",
    "white_df = df.select(['features', 'white_rating'])\n",
    "black_df = df.select(['features','black_rating'])\n",
    "\n",
    "\n",
    "splits = white_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='white_rating', maxIter=10)\n",
    "lr_model_white = lr.fit(train_df)\n",
    "lr_predictions = lr_model_white.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"white_rating\",\"features\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test data = 195.023\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model_white.evaluate(test_df)\n",
    "print(\"Mean Absolute Error on test data = %g\" % test_result.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.47096720746109827,8.918899342429652,-0.0020798690355112465]\n",
      "Intercept: 2244.52663209\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(lr_model_white.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_model_white.intercept))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------------------+\n",
      "|        prediction|black_rating|            features|\n",
      "+------------------+------------+--------------------+\n",
      "| 2664.722921080523|        2562|[-814.0,-1.0,-195.0]|\n",
      "| 2596.936504817829|        2468|[-684.0,-1.0,-450.0]|\n",
      "|2585.5119826562764|        2547|[-663.0,-1.0,-228.0]|\n",
      "| 2572.490484188143|        2533|[-638.0,-1.0,-285.0]|\n",
      "| 2572.646866159907|        2618|[-637.0,-1.0,-663.0]|\n",
      "+------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = black_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='black_rating', maxIter=10)\n",
    "lr_model_black = lr.fit(train_df)\n",
    "lr_predictions = lr_model_black.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"black_rating\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test data = 199.942\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model_black.evaluate(test_df)\n",
    "print(\"Mean Absolute Error on test data = %g\" % test_result.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.5249696788400996,7.330577332016597,-0.001802517594190855]\n",
      "Intercept: 2244.37668891\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(lr_model_black.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_model_black.intercept))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
